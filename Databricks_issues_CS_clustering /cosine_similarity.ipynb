{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a5e77a-a493-436f-a73e-6643f9d9137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff413f0-1e56-4984-ad12-d9d84c74c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: scipy in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: sentencepiece in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.1.95)\n",
      "Requirement already satisfied: nltk in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.20.1)\n",
      "Requirement already satisfied: filelock in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: joblib in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4bbb0b3-c03b-45bd-9f78-d845b598e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jproperties library installation issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Union with Null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spark ReadStream fails to infer schema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unable to execute Notebook commands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARR Customer CVS: Issue - Unable to grant read...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0            jproperties library installation issue \n",
       "1                                    Union with Null\n",
       "2             Spark ReadStream fails to infer schema\n",
       "3                Unable to execute Notebook commands\n",
       "4  ARR Customer CVS: Issue - Unable to grant read..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('databricks2.csv',usecols=['title'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ea5632-0af4-458b-8828-41e1c037180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urlextract in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (1.6.0)\n",
      "Requirement already satisfied: uritools in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from urlextract) (4.0.0)\n",
      "Requirement already satisfied: filelock in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from urlextract) (3.6.0)\n",
      "Requirement already satisfied: platformdirs in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from urlextract) (2.5.2)\n",
      "Requirement already satisfied: idna in /Users/ankush.singal/opt/anaconda3/lib/python3.9/site-packages (from urlextract) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dc576b-1d09-4105-be8d-7e13b4dacbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/ankush.singal/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from urlextract import URLExtract\n",
    "extractor = URLExtract()\n",
    "import contractions\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "# dictionary = {'\" \"':  ' ', \",\": ' ','-' : ' ',' \" ': ' ','()' : '',\n",
    "#                   '%' : '','#': '','\\[':'','\\]': '',\n",
    "#                   '\\\\(\\\\)':'','\\*':' ' ,'\\|':'',\n",
    "#                  '!':'','\\?':'','\\(\\)': '','/': '',\n",
    "#                   '\\)' : '', '\\(' : '', '\"': '', ':':'',\"'\": '','  +':' ',\n",
    "#                  }\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    #text = text.replace(dictionary,regex=True)\n",
    "    #to lowercase\n",
    "    text = str(text).lower()\n",
    "    #remove urls\n",
    "    urls = extractor.find_urls(text)\n",
    "    for url in urls:\n",
    "        text = text.replace(url, '')\n",
    "    #remove new lines\n",
    "    text = text.replace('\\\\n',' ')\n",
    "    #replacement\n",
    "    text = text.replace(re.escape(\"\\]\\[\"), \"\")\n",
    "    text = text.replace(re.escape(\"]\"), \"\")\n",
    "    #remove none meaningful    \n",
    "    text = re.sub(r'\\\\x[0-9a-f]{2}', '',text)\n",
    "    #remove emails\n",
    "    text = re.sub(r'\\S*@\\S*\\s?',' ',text)\n",
    "    #remove mentions\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    #contractions\n",
    "    text = contractions.fix(text)\n",
    "    #remove hashtags\n",
    "    text = re.sub(r'@\\S+', ' ', text)\n",
    "    #remove emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    #remove retweets\n",
    "    text = text.replace(r'rt', '')\n",
    "    #remove all punct\n",
    "    text = re.sub('[^A-za-z0-9]', ' ', text)\n",
    "    #remove extras whitespaces\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    #text = cleaning(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21132866-4b84-4c46-87c3-047091ebcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b75fca-c787-4c06-b83e-5ea690b4c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shorter_query(data,column,n):\n",
    "    data[column] = data[column].apply(lambda x:str(x).split(' '))\n",
    "    data = data[data[column].apply(lambda x:True if len(x) > n else False)]\n",
    "    data[column] = data[column].apply(lambda x:' '.join(x))\n",
    "    data = data.reset_index()\n",
    "    del data[\"index\"]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5073fcee-4b8a-4330-86ea-a3ea4682b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/zq0k80m94v5408fgfvkddv880000gp/T/ipykernel_65891/127429367.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column] = data[column].apply(lambda x:' '.join(x))\n"
     ]
    }
   ],
   "source": [
    "df = remove_shorter_query(df,\"title\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8042016f-acb8-498b-8dfe-86352ab87be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=df['title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd3321a-9a46-48a7-af84-a02b0b0c585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a04ab12c-9580-47db-aeb5-65e686b90c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a78b68c7-a83a-4f50-b9fd-c1a72d9e6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(result,convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24bd1c0-6df1-471d-9fd2-d255e834be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for embedding in embeddings:\n",
    "#     print(embeddings[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ddce2a8-b5d4-4114-bc45-b0934aecb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs failing with library not being installed on dataclusters \t\t jobs failing with library not being installed on dataclusters \t\t Score: 1.0000\n",
      "css sfmc 2203170040001201 adb cluster hung \t\t css sfmc 2203170040001201 adb cluster hung \t\t Score: 1.0000\n",
      "css sfmc 2203170040001201 adb cluster hung \t\t css sfmc 2203170040001201 adb cluster hung \t\t Score: 1.0000\n",
      "css sfmc 2203170040001201 adb cluster hung \t\t css sfmc 2203170040001201 adb cluster hung \t\t Score: 1.0000\n",
      "unexpected failure while waiting for the cluster \t\t unexpected failure while waiting for the cluster \t\t Score: 1.0000\n",
      "2204140050001360 job failure \t\t 2204140050001360 job failure \t\t Score: 1.0000\n",
      "clusters are holding too many connections \t\t clusters are holding too many connections \t\t Score: 1.0000\n",
      "attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t Score: 1.0000\n",
      "attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t Score: 1.0000\n",
      "attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t attributeerror module lib has no attribute x509_v_flag_cb_issuer_check  \t\t Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#compute the similarity scores\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "#compute/find the highest similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i] \n",
    "                                                             [j]})\n",
    "#sort the scores in decreasing order \n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(result[i],\n",
    "                                  result[j], pair['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db8554-4d9b-42df-8f2f-416b428f2792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8a518-841a-44b7-a77d-f608149e0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/an-intuitive-explanation-of-sentence-bert-1984d144a868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09341ca-e2f0-4885-9b95-dba7c93db980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(\n",
    "    [embeddings[0]],\n",
    "     embeddings[1:]\n",
    ")\n",
    "#https://github.com/jamescalam/transformers/blob/main/course/similarity/04_sentence_transformers.ipynb\n",
    "#https://github.com/jamescalam/transformers/blob/main/course/similarity/03_calculating_similarity.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
