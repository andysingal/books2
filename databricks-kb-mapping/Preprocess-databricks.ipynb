{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1982c69-9084-405a-9e1b-6336c0ed1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23dca114-ed9f-4d54-a73a-62b844fe5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kb_aws.json') as json_file:\n",
    "    data_list = json.load(json_file)\n",
    "\n",
    "data = data_list['hits'][\"hits\"]\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6826d6e-9c00-41ce-ad8e-fd338e821345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/zq0k80m94v5408fgfvkddv880000gp/T/ipykernel_46762/3175058616.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  df2 = json_normalize(data,max_level=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307, 7)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = json_normalize(data,max_level=1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2259f56b-95e8-4a33-b7cb-e97804b0a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('databricks_gcp_docs.json') as json_file:\n",
    "    data_list1 = json.load(json_file)\n",
    "\n",
    "data1 = data_list1['hits'][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9469b37b-dfaf-4791-883a-a5572d98c668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/zq0k80m94v5408fgfvkddv880000gp/T/ipykernel_46762/2944106821.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  df3 = json_normalize(data1,max_level=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1808, 8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = json_normalize(data1,max_level=1)\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c22ce2c-5c1c-4400-b1ba-ae82bc53dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('databricks_ms_azure_docs.json') as json_file:\n",
    "    data_list2 = json.load(json_file)\n",
    "\n",
    "data2 = data_list2['hits'][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "407f65ca-974e-41e1-8d60-97faed3139fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/zq0k80m94v5408fgfvkddv880000gp/T/ipykernel_46762/3146281941.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  df4 = json_normalize(data2,max_level=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = json_normalize(data2,max_level=1)\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ecf66cd2-5c87-46f2-bcb9-0210da0ce3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('databricks_ms_azure_kb.json') as json_file:\n",
    "    data_list3 = json.load(json_file)\n",
    "\n",
    "data3 = data_list3['hits'][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42ba0863-7569-4c57-89b3-3e5f44bd0bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/zq0k80m94v5408fgfvkddv880000gp/T/ipykernel_46762/1360268492.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead.\n",
      "  df5 = json_normalize(data3,max_level=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(309, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = json_normalize(data3,max_level=1)\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c17b466f-dd5c-4769-ae10-c5f50c318886",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_matrix = pd.concat([df2,df3,df4,df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f2e84169-845c-4a13-a2cb-1aaef022190a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>breadcrumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Databricks Knowledge Base Main Navigation Help...</td>\n",
       "      <td>https://kb.databricks.com/en_US/security/troub...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Databricks Knowledge Base Main Navigation Help...</td>\n",
       "      <td>https://kb.databricks.com/en_US/sql/cannot-vie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Databricks Knowledge Base Main Navigation Help...</td>\n",
       "      <td>https://kb.databricks.com/en_US/dev-tools/dbco...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks Knowledge Base Main Navigation Help...</td>\n",
       "      <td>https://kb.databricks.com/en_US/jobs/task-dese...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Databricks Knowledge Base Main Navigation Help...</td>\n",
       "      <td>https://kb.databricks.com/en_US/libraries/inst...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  \\\n",
       "0    Databricks Knowledge Base Main Navigation Help...   \n",
       "1    Databricks Knowledge Base Main Navigation Help...   \n",
       "2    Databricks Knowledge Base Main Navigation Help...   \n",
       "3    Databricks Knowledge Base Main Navigation Help...   \n",
       "4    Databricks Knowledge Base Main Navigation Help...   \n",
       "..                                                 ...   \n",
       "304  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "305  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "306  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "307  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "308  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "\n",
       "                                                   url breadcrumb  \n",
       "0    https://kb.databricks.com/en_US/security/troub...        NaN  \n",
       "1    https://kb.databricks.com/en_US/sql/cannot-vie...        NaN  \n",
       "2    https://kb.databricks.com/en_US/dev-tools/dbco...        NaN  \n",
       "3    https://kb.databricks.com/en_US/jobs/task-dese...        NaN  \n",
       "4    https://kb.databricks.com/en_US/libraries/inst...        NaN  \n",
       "..                                                 ...        ...  \n",
       "304  https://docs.microsoft.com/en-us/azure/databri...        NaN  \n",
       "305  https://docs.microsoft.com/en-us/azure/databri...        NaN  \n",
       "306  https://docs.microsoft.com/en-us/azure/databri...        NaN  \n",
       "307  https://docs.microsoft.com/en-us/azure/databri...        NaN  \n",
       "308  https://docs.microsoft.com/en-us/azure/databri...        NaN  \n",
       "\n",
       "[4424 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_matrix.rename(\n",
    "    columns=({'_source.title': 'title','_source.view_href':'url','_source.body': 'description','_source.breadcrumb':'breadcrumb'}), \n",
    "    inplace=True\n",
    ")\n",
    "single_matrix  = single_matrix.loc[:, [\"description\",\"url\",\"breadcrumb\"]]\n",
    "single_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9ea9dc1-3ee5-4607-94a0-812429e5001c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4424, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb89acf-8eac-4fcb-b115-9aad536260c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8d6e812-41c4-4788-885d-841ee420620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_type</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>search_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aws_doc</td>\n",
       "      <td>SELECT</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/spark...</td>\n",
       "      <td>time travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aws_doc</td>\n",
       "      <td>Delta Live Tables cookbook</td>\n",
       "      <td>https://docs.databricks.com/data-engineering/d...</td>\n",
       "      <td>dlt.create_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aws_doc</td>\n",
       "      <td>INSERT OVERWRITE DIRECTORY</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/spark...</td>\n",
       "      <td>insert overwrite ... partitions (a=x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aws_doc</td>\n",
       "      <td>Dates and timestamps</td>\n",
       "      <td>https://docs.databricks.com/spark/latest/dataf...</td>\n",
       "      <td>date minus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index_type                       title  \\\n",
       "0    aws_doc                      SELECT   \n",
       "1    aws_doc  Delta Live Tables cookbook   \n",
       "2    aws_doc  INSERT OVERWRITE DIRECTORY   \n",
       "3        NaN                         NaN   \n",
       "4    aws_doc        Dates and timestamps   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://docs.databricks.com/spark/latest/spark...   \n",
       "1  https://docs.databricks.com/data-engineering/d...   \n",
       "2  https://docs.databricks.com/spark/latest/spark...   \n",
       "3                                                NaN   \n",
       "4  https://docs.databricks.com/spark/latest/dataf...   \n",
       "\n",
       "                            search_text  \n",
       "0                           time travel  \n",
       "1                      dlt.create_table  \n",
       "2  insert overwrite ... partitions (a=x  \n",
       "3                               complex  \n",
       "4                            date minus  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(): \n",
    "    df_all = pd.read_csv('databrickssearcheswithwithoutclicks.csv')\n",
    "    # Take a subset\n",
    "    return df_all.loc[:, [\"index_type\",\"title\",\"url\",\"search_text\"]]\n",
    "df6 = load_data()\n",
    "\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2ba2557-c007-4bd0-9fff-187a513ec9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_type</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>search_text</th>\n",
       "      <th>description</th>\n",
       "      <th>breadcrumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>Workflows with jobs</td>\n",
       "      <td>https://docs.gcp.databricks.com/data-engineeri...</td>\n",
       "      <td>workflows with jobs</td>\n",
       "      <td>Workflows with jobs You can use a job to run a...</td>\n",
       "      <td>[Databricks Data Science &amp; Engineering guide, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>Workflows with jobs</td>\n",
       "      <td>https://docs.gcp.databricks.com/data-engineeri...</td>\n",
       "      <td>workflows with jobs</td>\n",
       "      <td>Workflows with jobs You can use a job to run a...</td>\n",
       "      <td>[Databricks Data Science &amp; Engineering guide, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>Workflows with jobs</td>\n",
       "      <td>https://docs.gcp.databricks.com/data-engineeri...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>Workflows with jobs You can use a job to run a...</td>\n",
       "      <td>[Databricks Data Science &amp; Engineering guide, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>Workflows with jobs</td>\n",
       "      <td>https://docs.gcp.databricks.com/data-engineeri...</td>\n",
       "      <td>workflows</td>\n",
       "      <td>Workflows with jobs You can use a job to run a...</td>\n",
       "      <td>[Databricks Data Science &amp; Engineering guide, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>Workflows with jobs</td>\n",
       "      <td>https://docs.gcp.databricks.com/data-engineeri...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>Workflows with jobs You can use a job to run a...</td>\n",
       "      <td>[Databricks Data Science &amp; Engineering guide, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>DESCRIBE SCHEMA</td>\n",
       "      <td>https://docs.gcp.databricks.com/spark/latest/s...</td>\n",
       "      <td>star schema</td>\n",
       "      <td>DESCRIBE SCHEMA Returns the metadata of an exi...</td>\n",
       "      <td>[Introduction to Databricks, Language-specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>ms_azure</td>\n",
       "      <td>find_in_set function</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>how to find the azure databricks dbu usage</td>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>pandas function APIs</td>\n",
       "      <td>https://docs.gcp.databricks.com/spark/latest/s...</td>\n",
       "      <td>out of memory</td>\n",
       "      <td>pandas function APIs pandas function APIs enab...</td>\n",
       "      <td>[Introduction to Databricks, Language-specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>ms_azure</td>\n",
       "      <td>xpath_string function</td>\n",
       "      <td>https://docs.microsoft.com/en-us/azure/databri...</td>\n",
       "      <td>typeerror 'str' object is not callable pyspark</td>\n",
       "      <td>Azure Azure Databricks Azure Azure Databricks ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>gcp_docs</td>\n",
       "      <td>concat function</td>\n",
       "      <td>https://docs.gcp.databricks.com/spark/latest/s...</td>\n",
       "      <td>concat</td>\n",
       "      <td>concat function Returns the concatenation of t...</td>\n",
       "      <td>[Introduction to Databricks, Language-specific...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3280 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index_type                  title  \\\n",
       "0      gcp_docs    Workflows with jobs   \n",
       "1      gcp_docs    Workflows with jobs   \n",
       "2      gcp_docs    Workflows with jobs   \n",
       "3      gcp_docs    Workflows with jobs   \n",
       "4      gcp_docs    Workflows with jobs   \n",
       "...         ...                    ...   \n",
       "3275   gcp_docs        DESCRIBE SCHEMA   \n",
       "3276   ms_azure   find_in_set function   \n",
       "3277   gcp_docs   pandas function APIs   \n",
       "3278   ms_azure  xpath_string function   \n",
       "3279   gcp_docs        concat function   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://docs.gcp.databricks.com/data-engineeri...   \n",
       "1     https://docs.gcp.databricks.com/data-engineeri...   \n",
       "2     https://docs.gcp.databricks.com/data-engineeri...   \n",
       "3     https://docs.gcp.databricks.com/data-engineeri...   \n",
       "4     https://docs.gcp.databricks.com/data-engineeri...   \n",
       "...                                                 ...   \n",
       "3275  https://docs.gcp.databricks.com/spark/latest/s...   \n",
       "3276  https://docs.microsoft.com/en-us/azure/databri...   \n",
       "3277  https://docs.gcp.databricks.com/spark/latest/s...   \n",
       "3278  https://docs.microsoft.com/en-us/azure/databri...   \n",
       "3279  https://docs.gcp.databricks.com/spark/latest/s...   \n",
       "\n",
       "                                         search_text  \\\n",
       "0                                workflows with jobs   \n",
       "1                                workflows with jobs   \n",
       "2                                         monitoring   \n",
       "3                                          workflows   \n",
       "4                                               jobs   \n",
       "...                                              ...   \n",
       "3275                                     star schema   \n",
       "3276      how to find the azure databricks dbu usage   \n",
       "3277                                   out of memory   \n",
       "3278  typeerror 'str' object is not callable pyspark   \n",
       "3279                                          concat   \n",
       "\n",
       "                                            description  \\\n",
       "0     Workflows with jobs You can use a job to run a...   \n",
       "1     Workflows with jobs You can use a job to run a...   \n",
       "2     Workflows with jobs You can use a job to run a...   \n",
       "3     Workflows with jobs You can use a job to run a...   \n",
       "4     Workflows with jobs You can use a job to run a...   \n",
       "...                                                 ...   \n",
       "3275  DESCRIBE SCHEMA Returns the metadata of an exi...   \n",
       "3276  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "3277  pandas function APIs pandas function APIs enab...   \n",
       "3278  Azure Azure Databricks Azure Azure Databricks ...   \n",
       "3279  concat function Returns the concatenation of t...   \n",
       "\n",
       "                                             breadcrumb  \n",
       "0     [Databricks Data Science & Engineering guide, ...  \n",
       "1     [Databricks Data Science & Engineering guide, ...  \n",
       "2     [Databricks Data Science & Engineering guide, ...  \n",
       "3     [Databricks Data Science & Engineering guide, ...  \n",
       "4     [Databricks Data Science & Engineering guide, ...  \n",
       "...                                                 ...  \n",
       "3275  [Introduction to Databricks, Language-specific...  \n",
       "3276                                                NaN  \n",
       "3277  [Introduction to Databricks, Language-specific...  \n",
       "3278                                                NaN  \n",
       "3279  [Introduction to Databricks, Language-specific...  \n",
       "\n",
       "[3280 rows x 6 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_df = df6.merge(right=single_matrix,on='url',how=\"inner\")\n",
    "mapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cb4d871-9d91-4d3b-94e3-1eabf366ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_df.to_csv('cleaned_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcc0d4e6-fded-4882-b01a-857bfa4cb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['index_type']\n",
    "df6[cols] = df6[cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac787e8d-73f0-41c7-9fd5-0f809af0e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datascienceparichay.com/article/pandas-emove-categories-from-a-categorical-column/#:~:text=You%20can%20use%20the%20Pandas,accessor%20to%20apply%20this%20function.&text=Pass%20the%20category%20or%20a,an%20argument%20to%20the%20function.\n",
    "df6[\"index_type\"] = df6[\"index_type\"].cat.remove_categories([\"aws kb\",\"apache_spark\",\"feeditem_1\",\"feeditem\",\"case\",\"knowledge__kav\",\"message\",\"blog\",\"user\",\"issue\",\"collaborationgroup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1adc2a8-6f63-43f0-8ace-4b8a01f8dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aws_doc     93610\n",
       "gcp_docs     2425\n",
       "ms_azure     1044\n",
       "ms_kb         158\n",
       "gcp_kb         69\n",
       "Name: index_type, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.index_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1572dd1-54c1-47a4-8d76-011dd114988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202170, 4)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "309c6994-f76f-44a9-8581-007b0561311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_matrix[single_matrix[\"_source.breadcrumb\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8da275-8c8d-4fec-b712-5cdadbea6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "# from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "# df_all = pd.DataFrame({'search_term':['hat','cat'], \n",
    "#                        'product_title':['hat stand','cat in hat']})\n",
    "\n",
    "# transformer = FeatureUnion([\n",
    "#                 ('search_term_tfidf', \n",
    "#                   Pipeline([('extract_field',\n",
    "#                               FunctionTransformer(lambda x: x['search_term'], \n",
    "#                                                   validate=False)),\n",
    "#                             ('tfidf', \n",
    "#                               TfidfVectorizer())])),\n",
    "#                 ('product_title_tfidf', \n",
    "#                   Pipeline([('extract_field', \n",
    "#                               FunctionTransformer(lambda x: x['product_title'], \n",
    "#                                                   validate=False)),\n",
    "#                             ('tfidf', \n",
    "#                               TfidfVectorizer())]))]) \n",
    "\n",
    "# transformer.fit(df_all)\n",
    "\n",
    "# search_vocab = transformer.transformer_list[0][1].steps[1][1].get_feature_names() \n",
    "# product_vocab = transformer.transformer_list[1][1].steps[1][1].get_feature_names()\n",
    "# vocab = search_vocab + product_vocab\n",
    "\n",
    "# print(vocab)\n",
    "# print(transformer.transform(df_all).toarray())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
